# -*- coding: utf-8 -*-
"""CS Proj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TmHmMFNorWefo1_IYUWemc0q4utFN-Et
"""

import pandas as pd
import numpy as np

df = pd.read_csv("startup_growth_investment_data.csv")

# clean USD column, standardize into #.## billions
# Find the number of years the company has been running

df["Invest Amt (USD) in Billions"] = (df["Investment Amount (USD)"] / 1e9).round(2)
df["Valuation (USD) in Billions"] = (df["Valuation (USD)"] / 1e9).round(2)
df["Number of Years Running"] = (2025-df["Year Founded"])

# Removing the Country, Raw Investment and Valuationa, and Year Founded Column
df = df.drop(["Country","Investment Amount (USD)","Valuation (USD)",
              "Year Founded"], axis=1)

df.to_csv("clean_stock.csv")



# Understanding the Data --- Check for linearity just in case

import seaborn as sns
sns.pairplot(df, kind='reg', diag_kind='kde')

# This concludes 0 linear relationship between the features

# Linear Regression --- Predicting Valution Using all other numerical values

# X and y
Y = df["Valuation (USD) in Billions"]
X = df.drop(["Startup Name","Industry", "Invest Amt (USD) in Billions"],axis=1)

# Intercept
X["intercept"] = 1

X

# Finding Correlation, removing anything above 0.8
mat = X.corr()
mat

# Scaling and Standardizing

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# OLS and Predicting on Test Data
def ols (X, Y):
    # Numeric the matrix X, take away NaN vals
    X = X.apply(pd.to_numeric, errors='coerce')
    # X transpose
    Xt = X.T
    # X'X
    XtX = Xt@X
    # X'X)^(-1)
    XtX_inv = np.linalg.inv(XtX)
    # (X'X)^(-1) * X'
    XtX_inv_Xt = XtX_inv @ Xt
    # Final B
    B = XtX_inv_Xt @ Y
    # Turn into np array
    B = np.array(B)
    return B
print(ols(X,Y))

def pred (newX, B):
    newX = newX.apply(pd.to_numeric, errors='coerce')
    newY = newX @ B
    return newY
print(pred(X, ols(X,Y)))

# KFold Testing and making a new Data Frame

from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error

kf = KFold(n_splits = 10, shuffle=False)
res = []
side = []

for i, (train_index, test_index) in enumerate(kf.split(X)):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    Ytrain = Y.iloc[train_index]
    Ytest = Y.iloc[test_index]

    coefficients = ols(X_train, Ytrain)
    predict = pred(X_test, coefficients)

    rmse = np.sqrt(mean_squared_error(Ytest, predict))
    side.append([predict, Ytest])
    res.append([coefficients[0], coefficients[1], coefficients[2], coefficients[3],
                coefficients[4], coefficients[5], rmse])
    resdf = pd.DataFrame(res, columns=["intercept","Funding Rounds",
                                       "Number of Investors", "Growth Rate (%)",
                                       "Valuation (USD) in Billions",
                                       "Number of Years Running", "RMSE"])

print(resdf)

# Average RMSE
sum(resdf["RMSE"])/len(resdf["RMSE"])

"""### **USING SUPPORT VECTOR MACHINE AS AN ALTERNATIVE**

Defining Success, adding columns
"""

df['Outcome'] = 'Undefined'  # Initialize a new column with a default value

df

from google.colab import drive
drive.mount('/content/drive')

# Rule 1: Growth rate >= 60% is considered success
df.loc[df['Growth Rate (%)'] >= 60, 'Outcome'] = 'Success'

# Rule 2: Funding rounds based on number of years running
df.loc[(df['Number of Years Running'] >= 6) & (df['Funding Rounds'] >= 4), 'Outcome'] = 'Success'
df.loc[(df['Number of Years Running'] < 6) & (df['Funding Rounds'] >= 2), 'Outcome'] = 'Success'

# Any remaining rows are classified as failure
df.loc[df['Outcome'] == 'Undefined', 'Outcome'] = 'Failure'

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC  # For classification
from sklearn.svm import SVR  # For regression
from sklearn.metrics import accuracy_score  # For classification
from sklearn.metrics import mean_squared_error  # For regression
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""actual training"""

# X and y
Y = df["Outcome"]
X = df.drop(["Startup Name","Industry", "Invest Amt (USD) in Billions","Outcome"],axis=1)

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.svm import SVC  # For classification

# Assuming you have defined 'X' and 'y' (categorical target variable)

# Scaling and Standardizing
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Encode target variable
le = LabelEncoder()
y_encoded = le.fit_transform(Y)

# Assuming 'X' is your feature matrix and 'y' is your target variable

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Create and train SVM regressor
model = SVC(kernel='linear', C=1)  # Initialize the SVM model with desired kernel and hyperparameters
model.fit(X_train, y_train)  # Train the model on the training data

# Make predictions
y_pred_encoded = model.predict(X_test)

# Evaluate performance
accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy
print(f"Accuracy: {accuracy}")

print(classification_report(y_test, y_pred))  # Print classification report (precision, recall, F1-score)

print(confusion_matrix(y_test, y_pred))  # Print confusion matrix

# Assuming 'y_test' contains the actual values and 'y_pred' contains the predicted values

# Create a DataFrame for comparison
df_comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

# Print the DataFrame
print(df_comparison)

# Create a boolean mask for non-matching predictions
non_matching_mask = y_test != y_pred

# Filter the actual and predicted values using the mask
actual_non_matching = y_test[non_matching_mask]
predicted_non_matching = y_pred[non_matching_mask]

# Create a DataFrame for comparison (optional)
df_non_matching = pd.DataFrame({'Actual': actual_non_matching, 'Predicted': predicted_non_matching})

# Print the non-matching values
print(df_non_matching)  # Or print using a loop as before